{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now to build some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import everything\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull in our formatted train data\n",
    "df = pd.read_csv('out_train_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#and our formatted test data\n",
    "df1 = pd.read_csv('out_test_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.ix[df1.Species.str.contains(\"UNSPECIFIED CULEX\"), 'Species'] = \"CULEX PIPIENS/RESTUANS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's first establish our y variable\n",
    "X = df.drop(\"WnvPresent\", axis=1)\n",
    "y = df.WnvPresent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating a variable to determine what the variance in temperature was on any given day\n",
    "X[\"TVar\"] = X[\"Tmax\"] - X[\"Tmin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#and the same for our test data\n",
    "df1[\"TVar\"] = df1['Tmax'] - df1['Tmin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converting species and trap to categorical data\n",
    "X.Species = X.Species.astype('category')\n",
    "\n",
    "# X.Species = X.Species.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.Species = df1.Species.astype('category')\n",
    "# df1.Species = df1.Species.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.Trap = X.Trap.astype('category')\n",
    "# X.Trap = X.Trap.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.Trap = df1.Trap.astype('category')\n",
    "# test.Trap = test.Trap.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.concat([X, pd.get_dummies(X.Species, drop_first=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.concat([test, pd.get_dummies(test.Species, drop_first=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop the variables we're not going to use\n",
    "X.head()\n",
    "X = X.drop(['Unnamed: 0', 'Date', 'Address', 'Block', 'Street', 'AddressNumberAndStreet', 'AddressAccuracy', 'Tavg', 'Tmin', 'NumMosquitos', 'DewPoint', 'Trap', 'Species'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#same with test\n",
    "test = test.drop(['Unnamed: 0','Id', 'Date', 'Address', 'Block', 'Street', 'AddressNumberAndStreet', 'AddressAccuracy', 'Tavg', 'Tmin', 'DewPoint', 'Trap', 'Species'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#let's check the dataframe to make sure they're both the same\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#yep, they are\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's start importign everything\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scaling the data to make sure all our data is on the same scale\n",
    "X = pd.concat([X, StandardScaler().fit_transform(X[['Tmax', 'PrecipTotal', 'AvgSpeed', 'length_of_day', 'TVar']])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = StandardScaler().fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#IMPORT ALL THE THINGS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#set our parameters for gradient boosting\n",
    "gbc = GradientBoostingClassifier(max_features='sqrt',n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#establish names for our confusion matrix\n",
    "names = [\"present\", \"not present\", \"predicted present\", \"predicted not present\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pull up this monster of a function again to take a look at our train data and generate the model we think is best\n",
    "def evaluate_model(model, X, y, names, test):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=7)\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    print model.score(X_test, Y_test)\n",
    "    Y_pp = pd.DataFrame(model.predict_proba(X_test), columns=['class_0_pp','class_1_pp'])\n",
    "    Y_pp['pred_class_thresh10'] = [1 if x >= 0.05 else 0 for x in Y_pp.class_1_pp.values]\n",
    "    X_test_df = pd.DataFrame(X_test)\n",
    "    conmat = np.array(confusion_matrix(Y_test, Y_pp.pred_class_thresh10, labels=[1,0]))\n",
    "    confusion = pd.DataFrame(conmat, index=[names[0:2]],\n",
    "                         columns=[names[2:]]) \n",
    "    print(Y_pp.iloc[0:10])\n",
    "    print confusion\n",
    "    print(classification_report(Y_test, Y_pp.pred_class_thresh10))\n",
    "    print Y_pp.shape\n",
    "    print X_test_df.head()\n",
    "    \n",
    "    Y_score = model.decision_function(X_test)\n",
    "\n",
    "    FPR = dict()\n",
    "    TPR = dict()\n",
    "    ROC_AUC = dict()\n",
    "\n",
    "# For class 1, find the area under the curve\n",
    "    FPR[1], TPR[1], _ = roc_curve(Y_test, Y_score)\n",
    "    ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "# Plot of a ROC curve for class 1 (has_cancer)\n",
    "    plt.figure(figsize=[11,9])\n",
    "    plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.title('Receiver operating characteristic for WNV detection', fontsize=18)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return \"cross val mean score is\", cross_val_score(model, X_train, Y_train, cv=5).mean()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "evaluate_model(gbc, X, y, names, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep model for submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fit the model and get the predicted probabilities\n",
    "model = gbc.fit(X, y)\n",
    "y_pred = model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#also get the predictions in general\n",
    "y_predicted = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#just a tiny peak at what the model thought were the most important features\n",
    "#looks like it's species, trap and length of day\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating a dataframe for the y_preds\n",
    "y_preds = pd.DataFrame(data=y_pred, columns=[\"WnvNotPresent\", \"WnvPresent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a new dataframe merging all our data\n",
    "df_out = pd.merge(df1, y_preds[['WnvPresent']], how = 'left', left_index=True, right_index=True )\n",
    "df_out = df_out[['Id', 'WnvPresent']]\n",
    "df_out.to_csv('dummies_unscaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#and one for plotting graphs!\n",
    "df_plot = pd.merge(df1, y_preds[['WnvPresent']], how='left', left_index = True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the one for plot needs very specific columns\n",
    "#but we also want to set a threshold for where we think the city of Chicago should spray\n",
    "#we also wanted the date to be manipulatable \n",
    "df_plot = df_plot[['Longitude', 'Latitude', 'Trap', 'Date', 'WnvPresent']]\n",
    "df_plot[\"y_or_n\"] = [1 if x > 0.3 else 0 for x in df_plot.WnvPresent]\n",
    "df_plot['Date'] = pd.to_datetime(df_plot['Date'])\n",
    "df_plot['year'] = df_plot.Date.dt.year\n",
    "df_plot['month'] = df_plot.Date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#and let's save that\n",
    "df_plot.to_csv('dfplot_214.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
